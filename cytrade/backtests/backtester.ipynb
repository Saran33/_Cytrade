{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple example of batch-learning LDA Classification for a single asset, along with Kelly critereon for position sizing, for comparison to streaming examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import pandas as pd\n",
    "import pyfolio as pf\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from pprint import pprint as pp\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import cytrader as bt\n",
    "import cytrader.analyzers as btanalyzers\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import sklearn\n",
    "from joblib import dump, load\n",
    "\n",
    "from histData import binance_bars\n",
    "from utils.tools import to_utc\n",
    "from features import add_hist_features\n",
    "# from features_py import add_hist_features\n",
    "from mlPipelines import ttsplit, feat_pipe1, lda_pipe\n",
    "\n",
    "from strategies import Classifier, KellyML, SMAStrategy\n",
    "from backtest import BinanceCommision, SignalData, format_time\n",
    "\n",
    "sk_ver = sklearn.__version__\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comission = 0.001\n",
    "\n",
    "# class to define the columns we will provide\n",
    "class SignalData(bt.feeds.PandasData):\n",
    "    \"\"\"\n",
    "    Define pandas DataFrame structure\n",
    "    \"\"\"\n",
    "    OHLCV = ['open', 'high', 'low', 'close']\n",
    "    cols = OHLCV + ['predicted']\n",
    "\n",
    "    # create lines\n",
    "    lines = tuple(cols)\n",
    "    # define parameters\n",
    "    params = {c: -1 for c in cols}\n",
    "    params.update({'datetime': None})\n",
    "    params = tuple(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=['BTCUSDT']\n",
    "interval='1h'\n",
    "start_dt='2017-01-01'\n",
    "end_dt=None\n",
    "vol_window=24*30\n",
    "test_size=0.2\n",
    "start_nav=100000\n",
    "\n",
    "local_csv = False\n",
    "save_csv = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = to_utc(start_dt)\n",
    "print (\"START DATE:\", start_dt)\n",
    "end_dt = pytz.utc.localize(dt.utcnow()) if not end_dt else to_utc(end_dt)\n",
    "print(\"END DATE:\", end_dt)\n",
    "print(\"TICKERS:\", tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = {}\n",
    "\n",
    "if not local_csv:\n",
    "    for ticker in tickers:\n",
    "        sec = binance_bars(symbol=ticker, interval=interval,\n",
    "                            start_dt=start_dt, end_dt=end_dt, limit=None, dtype='df');\n",
    "\n",
    "else:\n",
    "    for ticker in tickers:\n",
    "        sec = pd.read_csv('../csv_files/BTCUSDT_1h_2017-08-17_2022-05-10.csv',\n",
    "                        low_memory=False, index_col=['DateTime'], parse_dates=['DateTime'], infer_datetime_format=True)\n",
    "sets[ticker] = sec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in sets:\n",
    "    dset = add_hist_features(ticker, sec, interval=interval, vol_window=vol_window, test_size=test_size)\n",
    "    sets[ticker] = dset\n",
    "    \n",
    "    if save_csv:\n",
    "        str_start = dset.index.min().strftime('%Y-%m-%d')\n",
    "        str_end = dset.index.max().strftime('%Y-%m-%d')\n",
    "        f_name = f'csv_files/{ticker}_{interval}_{str_start}_{str_end}.csv'\n",
    "        dset.to_csv(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets[ticker].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets['BTCUSDT'][['Price_Returns', 'target', 'Kalman_Filter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker, dset in sets.items():\n",
    "    X_train, X_test, y_train, y_test = ttsplit(dset, test_size)\n",
    "\n",
    "    feat_pipe = feat_pipe1(dset)\n",
    "    X_train = feat_pipe.fit_transform(X_train)\n",
    "    X_test = feat_pipe.transform(X_test)\n",
    "\n",
    "    model = lda_pipe().fit(X_train, y_train)\n",
    "    model_name = f'../models/LDA_{interval}_{ticker}_{dt.now().strftime(\"%Y_%m_%d-%H_%M\")}_skl{sk_ver}.joblib'\n",
    "    \n",
    "    dump(model, model_name)\n",
    "    model = load(model_name)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    print('')\n",
    "    print(ticker, \"Accuracy:\",\"{:.2%}\".format(accuracy_score(y_test, predictions)))\n",
    "    print (classification_report(y_test, predictions, zero_division=0))\n",
    "    display(pd.DataFrame({'Test Set':y_test, 'Predictions': predictions}))\n",
    "\n",
    "    train_len = int(len(dset) * (1-test_size))\n",
    "    train_set, test_set = dset.iloc[0:train_len].copy(),dset.iloc[train_len:len(dset)].copy()\n",
    "\n",
    "    test_set['predicted'] = predictions\n",
    "\n",
    "    sets[ticker] = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comission = 0.001\n",
    "cerebro = bt.Cerebro()\n",
    "comminfo = BinanceCommision()\n",
    "# comminfo = FixedCommisionScheme()\n",
    "cerebro.broker.addcommissioninfo(comminfo)\n",
    "cerebro.broker.setcash(start_nav)\n",
    "print (\"Opening NAV: ${:,.2f}\".format(start_nav))\n",
    "\n",
    "for ticker in sets:\n",
    "    bt_df = sets[ticker]\n",
    "    bt_df.index.name = 'datetime'\n",
    "    bt_data = SignalData(dataname=bt_df)\n",
    "    cerebro.adddata(bt_data, name=ticker)\n",
    "\n",
    "cerebro.addstrategy(KellyML, n_positions=1, min_positions=0, \n",
    "                    verbose=True, kel_bounds=[0., 1.], kel_window=24*30)\n",
    "# cerebro.addstrategy(SMAStrategy, n_positions=1, min_positions=0, \n",
    "#                     verbose=True, ma_window=60, kel_bounds=[0., 1.], kel_window=90)\n",
    "                    \n",
    "cerebro.addanalyzer(bt.analyzers.SQN, _name='sqn')\n",
    "cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "cerebro.addanalyzer(btanalyzers.Transactions, _name = \"trans\")\n",
    "cerebro.addanalyzer(btanalyzers.TradeAnalyzer, _name = \"trades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "results = cerebro.run()\n",
    "ending_value = cerebro.broker.getvalue()\n",
    "duration = time() - start\n",
    "n_trades = len(results[0].analyzers.trans.get_analysis()) \n",
    "\n",
    "print (\"Test Start:\", bt_df.index.min())\n",
    "print (\"Test End:\", bt_df.index.max())\n",
    "test_dt_len = ((bt_df.index.max() - bt_df.index.min()).total_seconds())/(24*60*60)\n",
    "print (f\"Days: {test_dt_len:,.2f}\")\n",
    "\n",
    "print (\"Opening NAV: ${:,.2f}\".format(start_nav))\n",
    "print(f'Closing NAV ${ending_value:,.2f}')\n",
    "gross_ret = (ending_value/start_nav)-1\n",
    "print (\"Gross Return: {:,.2%}\".format(gross_ret))\n",
    "print(f'Duration: {format_time(duration)}')\n",
    "print(f'Trades: {n_trades:,}')\n",
    "print('System Quality Number: ', results[0].analyzers.sqn.get_analysis())\n",
    "print('Total Comission: ${:,.2f}'.format(n_trades*comission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Trades: ')\n",
    "# pp(results[0].analyzers.trades.get_analysis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pyfolio inputs\n",
    "pyfolio_analyzer = results[0].analyzers.getbyname('pyfolio')\n",
    "returns, positions, transactions, gross_lev = pyfolio_analyzer.get_pf_items()\n",
    "\n",
    "returns.to_hdf('backtrader.h5', 'returns')\n",
    "positions.to_hdf('backtrader.h5', 'positions')\n",
    "transactions.to_hdf('backtrader.h5', 'transactions/')\n",
    "gross_lev.to_hdf('backtrader.h5', 'gross_lev')\n",
    "\n",
    "bench_name = 'CBBTCUSD' # 'SP500'\n",
    "benchmark = web.DataReader(bench_name, 'fred', returns.index.min(), returns.index.max()).squeeze()\n",
    "benchmark = benchmark.pct_change().tz_localize('UTC')\n",
    "\n",
    "daily_tx = transactions.groupby(level=0)\n",
    "longs = daily_tx.value.apply(lambda x: x.where(x>0).sum())\n",
    "shorts = daily_tx.value.apply(lambda x: x.where(x<0).sum())\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "df = returns.to_frame('Strategy').join(benchmark.to_frame(f'Benchmark ({bench_name})'))\n",
    "df.add(1).cumprod().sub(1).plot(ax=axes[0], title='Cumulative Return')\n",
    "\n",
    "longs.plot(label='Long',ax=axes[1], title='Positions')\n",
    "shorts.plot(ax=axes[1], label='Short')\n",
    "positions.cash.plot(ax=axes[1], label='PF Value')\n",
    "axes[1].legend()\n",
    "sns.set()\n",
    "sns.despine()\n",
    "fig.tight_layout();\n",
    "\n",
    "pf.create_full_tear_sheet(returns,\n",
    "                        transactions=transactions,\n",
    "                        positions=positions,\n",
    "                        benchmark_rets=benchmark.fillna(0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28f04388d61dce6749209f1587241d3519bab6d846fafa4ca0f5f855d5a17c2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('btenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
